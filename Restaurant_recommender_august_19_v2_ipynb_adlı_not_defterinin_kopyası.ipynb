{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0uQis7d4Lzyy14PfJXGdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tugrulyavuzates/Odev/blob/master/Restaurant_recommender_august_19_v2_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task: Generate Meaningful Restaurant Recommendations"
      ],
      "metadata": {
        "id": "gkF-p4B1RjCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSBOCtUJP28H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import linear_kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/TripAdvisor_RestauarantRecommendation.csv')"
      ],
      "metadata": {
        "id": "1EaCanEESJAg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b3d511fe-8dfd-4c4f-9e83-95ff755fb3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/TripAdvisor_RestauarantRecommendation.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-968e4307ef24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/TripAdvisor_RestauarantRecommendation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/TripAdvisor_RestauarantRecommendation.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n",
        "#trim \"reviews\" from No of Reviews\n",
        "#get the first number from \"Reviews\" column\n",
        "#drop \"Menu\", \"Contact Number\", \"Trip_advisor Url\""
      ],
      "metadata": {
        "id": "MI-GkjMwSyY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "dw_1L4jiSz0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df.copy()\n",
        "df_copy = df_copy.drop(['Menu', 'Contact Number', 'Trip_advisor Url'], axis=1)"
      ],
      "metadata": {
        "id": "9f_30xnVS8cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.head()"
      ],
      "metadata": {
        "id": "6GPiRNL0UK02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.isnull().sum()"
      ],
      "metadata": {
        "id": "RPhMZe72ULyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_copy.Reviews.unique())"
      ],
      "metadata": {
        "id": "3rzk6GDzUbfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_copy['No of Reviews'].unique())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QXYdBIcMV3Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_copy[df_copy.Reviews == 'No review'])"
      ],
      "metadata": {
        "id": "YOsps0gkVFm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_copy[df_copy['No of Reviews'] == 'Undefined Number'])"
      ],
      "metadata": {
        "id": "3fOCSU2sVZgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df_copy.drop([1744,2866])\n",
        "df_copy = df_copy.reset_index(drop=True)\n",
        "df_copy"
      ],
      "metadata": {
        "id": "AJpi8BHFWKdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.Comments = df_copy.Comments.fillna('')"
      ],
      "metadata": {
        "id": "KYBywzDVWXB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.Type = df_copy.Type.fillna(df_copy.Type.value_counts().index[0])"
      ],
      "metadata": {
        "id": "08xzeb4IWrPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.isnull().sum()"
      ],
      "metadata": {
        "id": "8-xHp02rXxV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#********* To better see the types of cuisines and do operations on them more easily we append them to a list and then convert that list to a pandas series ***************\n",
        "\n",
        "types = []\n",
        "for i in range(len(df_copy)):\n",
        "  if type(df_copy.Type[i]) == str:\n",
        "    types.append(df_copy.Type[i].split(','))\n",
        "flat_list = list(itertools.chain(*types))\n",
        "series = pd.Series(flat_list)"
      ],
      "metadata": {
        "id": "SP-tSxVfX5Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = series.value_counts()[:10].plot(kind = \"pie\", shadow = True, cmap = plt.get_cmap('Spectral'), figsize=(10,10))\n",
        "ax.set_ylabel('Cuisine Types')\n",
        "plot = ax.set_title('Top 10 Cuisine Types by Entry')\n",
        "#"
      ],
      "metadata": {
        "id": "7ZKD2U5wZx3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'series' is already defined and contains the flat list of cuisines\n",
        "\n",
        "# Step 1: Get the top 10 most frequent types\n",
        "ax = series.value_counts()[:10].plot(\n",
        "    kind='pie',           # Plot as a pie chart\n",
        "    shadow=True,          # Add shadow for visual effect\n",
        "    cmap=plt.get_cmap('Spectral'),  # Use the 'Spectral' colormap\n",
        "    figsize=(10, 10)      # Set the figure size\n",
        ")\n",
        "\n",
        "# Step 2: Customize the plot\n",
        "ax.set_ylabel('')  # Optional: Remove y-label for a cleaner look\n",
        "ax.set_title('Top 10 Cuisine Types by Entry')  # Set the title\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XwM5mjk2bnyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"No of Restaurant serving\":series.value_counts()}).head(10)"
      ],
      "metadata": {
        "id": "3Onull0kcCjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List Comprehension\n",
        " important!!!\n"
      ],
      "metadata": {
        "id": "FD3nSYTtiQBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy['State'] = [i.split(',')[-1].split(\" \")[1] for i in df_copy.Location]\n",
        "df_copy['Zipcode'] = [i.split(',')[-1].split(\" \")[-1] for i in df_copy.Location]\n",
        "df_copy['City'] = [\",\".join(i.split(\",\")[:-1]) for i in df_copy.Location] #********************************* Beautifullll for a newbieee!!!!! **************************************\n",
        "df_copy = df_copy.drop(['Location'], axis=1)\n",
        "\n",
        "df_copy"
      ],
      "metadata": {
        "id": "7bv7TmMQcg8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_copy[['City', 'State', 'Zipcode']].isnull().sum())"
      ],
      "metadata": {
        "id": "46fSyvvlk-rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df_copy.drop(df_copy[df_copy['State']==''].index[0])\n",
        "df_copy.State.value_counts()"
      ],
      "metadata": {
        "id": "21Hv2NzJmRHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = df_copy.State.value_counts().plot(kind = \"bar\", color= 'Purple', figsize=(10,5))\n",
        "ax.set_ylabel('Number of Restaurants')\n",
        "ax.set_xlabel('States')\n",
        "plot = ax.set_title('Number of Restaurants in each State')"
      ],
      "metadata": {
        "id": "AlHK9bGnm4Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'No of Restaurants per State':df_copy.State.value_counts()}).head(10)"
      ],
      "metadata": {
        "id": "trDkFyQFoZgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Ranking the best (most highly rated) restaurants from each state\n",
        "Now most highly rated restaurant has to include two factors: -\n",
        "Number of people who reviewed\n",
        "Review Ratings on 5\n"
      ],
      "metadata": {
        "id": "GXtIaVVUpV-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy['Reviews'] = [float(i.split(\" \")[0]) for i in df_copy.Reviews]\n",
        "df_copy['No of Reviews'] = [int(i.split(\" \")[0].replace(\",\",\"\")) for i in df_copy['No of Reviews']]\n",
        "\n",
        "df_copy"
      ],
      "metadata": {
        "id": "Us9gXm9-o6CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df_copy.drop([1744,2866])"
      ],
      "metadata": {
        "id": "niokZIIGsJfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy['weighted_ratings'] = df_copy['Reviews'] * df_copy['No of Reviews']"
      ],
      "metadata": {
        "id": "lXi-TvLUs1Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weighted Ratings Calculation:\n",
        "The weighted_ratings is calculated as follows:\n",
        "\n",
        "**kalÄ±n metin**\n",
        "df['weighted_ratings'] = df.Reviews * df['No of Reviews']\n",
        "Reviews: This might represent the average rating given by reviewers.\n",
        "No of Reviews: This represents the number of reviews a particular item (e.g., product, movie, etc.) received.\n",
        "Weighted Ratings Explained:\n",
        "The weighted_ratings is essentially the total score or total rating points calculated by multiplying the average rating by the number of reviews. This gives more weight to ratings that have a larger number of reviews, which makes sense because a rating with more reviews is generally more reliable than a rating based on just a few reviews.\n",
        "Why the Maximum Might Be Selected:\n",
        "Given this calculation, selecting the maximum weighted_ratings could make sense in certain contexts:\n",
        "\n",
        "Best Overall Rating: The maximum weighted_ratings might represent the item that received the most total positive feedback, considering both the number of reviews and the average rating.\n",
        "\n",
        "Dominant Opinion: Since weighted_ratings is a product of the average rating and the number of reviews, a high value suggests both a high average rating and a significant number of reviews. Therefore, selecting the maximum could highlight the most positively received item.\n",
        "\n",
        "Is There a Method Like This?\n",
        "While this approach is not standard in statistical analysis, it is a practical method in scenarios like product reviews, where:\n",
        "\n",
        "The highest weighted_ratings can represent the product with the most significant overall positive sentiment.\n",
        "Summary:\n",
        "Purpose of Maximum: Selecting the maximum weighted_ratings likely aims to identify the item that not only has a high average rating but also a large number of reviewers backing that rating.\n",
        "Context-Specific Logic: This method isn't about finding a statistical mean but rather about identifying the most robustly positive response within your dataset.\n",
        "If the analysis is intended to find the item that stands out most in terms of positive feedback (both in terms of quantity and quality), then using the maximum of weighted_ratings is reasonable."
      ],
      "metadata": {
        "id": "GbAnyr6lbMwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy['weighted_ratings']"
      ],
      "metadata": {
        "id": "vLsvR_1JXYD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df_copy.State.unique().flatten()\n",
        "labels\n"
      ],
      "metadata": {
        "id": "pZt2mKiAZB02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_vote_share_list = [df_copy[df_copy.State == i].weighted_ratings.max() for i in labels]\n",
        "avg_wt_ratings = pd.DataFrame({'State':labels, 'Average Weighted Ratings':average_vote_share_list})\n",
        "plot = sns.catplot(x='State', y=\"Average Weighted Ratings\", kind = 'bar', data= avg_wt_ratings, palette =\"rocket\")\n",
        "plt.title('Best Restaurant Among States')\n",
        "plt.gcf().set_size_inches(9, 6)"
      ],
      "metadata": {
        "id": "eYzsWzLZZpXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy[df_copy['weighted_ratings']==df_copy['weighted_ratings'].max()]"
      ],
      "metadata": {
        "id": "dCPPgv07c-he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy[df_copy['No of Reviews'] == df_copy['No of Reviews'].max()]"
      ],
      "metadata": {
        "id": "nrNz3WXBd586"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_vote_share_list = [df_copy[df_copy.State == i]['No of Reviews'].sum() for i in labels]\n",
        "total_vote_share = pd.DataFrame({'State':labels, 'Total Weighted Ratings':total_vote_share_list})\n",
        "plot = sns.catplot(x='State', y=\"Total Weighted Ratings\", kind = 'bar', data= total_vote_share, palette =\"rocket\")\n",
        "plt.title('Best Restaurant Among States')\n",
        "plt.gcf().set_size_inches(9, 6)"
      ],
      "metadata": {
        "id": "WTXT6LWZeslQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df_copy['City'].unique().flatten()\n",
        "total_vote_share_list = [df_copy[df_copy['City']==i].weighted_ratings.sum() for i in labels]\n",
        "total_wt_ratings = pd.DataFrame({'City':labels, 'Total Weighted Ratings': total_vote_share_list})\n",
        "total_wt_ratings = total_wt_ratings.sort_values(by=['Total Weighted Ratings'],ascending=False).head(5)\n",
        "plot = sns.catplot(x='City', y=\"Total Weighted Ratings\", kind=\"bar\", data=total_wt_ratings, palette=\"cubehelix\")\n",
        "plt.title(\"Top 5 Cities For Food\")\n",
        "plt.gcf().set_size_inches(9, 6)"
      ],
      "metadata": {
        "id": "EZKFQ-0RgLJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Our Main Feature - Comments\n",
        "df.Comments"
      ],
      "metadata": {
        "id": "ESR-9QrZhGaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['Comments'])\n"
      ],
      "metadata": {
        "id": "768UnE2lnENx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "### Construct the required tf-idf matrix by fitting and transforming the data\n",
        "tfidf_matrix = tfidf.fit_transform(df.Comments)\n",
        "\n",
        "### Output Shape of tf-idf matrix\n",
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "ZOdntXsBmrqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "W2D58qc7msq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(df_copy.index, index= df_copy.Name).drop_duplicates()\n",
        "indices"
      ],
      "metadata": {
        "id": "kLd_xQjung48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(name, cosine_sim=cosine_sim):\n",
        "\n",
        "    ### Index of the restaurant which matches the name\n",
        "    idx = indices[name]\n",
        "\n",
        "    ### Get the pairwise similarity\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    ### Sort the restaurants based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    ### Get the similarity scores of the 10 Most similar restuarants\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    ### Get the restauarant inidices\n",
        "    restaurant_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    ### Resturn the Top 10 most similar restaurants\n",
        "    return df['Name'].iloc[restaurant_indices]"
      ],
      "metadata": {
        "id": "My0MjDG1nvNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_recommendations('Coach House Diner')"
      ],
      "metadata": {
        "id": "4bn-S3vkpFi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: combine cosine similarity with another feature like cuisine type\n",
        "def get_hybrid_recommendations(name, cosine_sim=cosine_sim, df=df):\n",
        "    if name not in indices:\n",
        "        return \"Restaurant not found. Please check the name and try again.\"\n",
        "\n",
        "    idx = indices[name]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    restaurant_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    recommended_restaurants = df.iloc[restaurant_indices]\n",
        "\n",
        "    # Optionally, you can filter or rank these further by another feature\n",
        "    # e.g., Filter by a specific cuisine type or sort by average rating\n",
        "    # recommended_restaurants = recommended_restaurants[recommended_restaurants['Cuisine'] == 'Italian']\n",
        "    # recommended_restaurants = recommended_restaurants.sort_values(by='Rating', ascending=False)\n",
        "\n",
        "    return recommended_restaurants['Name']\n"
      ],
      "metadata": {
        "id": "Ici9aLgNpI47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_hybrid_recommendations('Coach House Diner')"
      ],
      "metadata": {
        "id": "fzDUgjg5sm4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zf-Quw3HsxDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}